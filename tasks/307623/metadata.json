{
    "time_to_develop_prompt": "> 40",
    "programming_language": "C++",
    "task_type": "Enhancement",
    "difficulty": "3",
    "estimated_skill_requirements": "Language-Specific Features,Software Engineering Best Practices,Data Structure and Algorithms",
    "user_prompt": "Base Code:\n```cpp\n// ThreadPool.h\n#ifndef THREADPOOL_H\n#define THREADPOOL_H\n\n#include <vector>\n#include <thread>\n#include <queue>\n#include <functional>\n#include <future>\n#include <mutex>\n#include <condition_variable>\n#include <atomic>\n\n// Struct to represent a Task with priority and order for FIFO within the same priority\nstruct Task {\n    Priority priority;\n    size_t order;\n    std::function<void()> func;\n\n    bool operator<(const Task& other) const {\n        // Higher priority tasks come first\n        if (priority != other.priority)\n            return priority > other.priority;\n        // Within same priority, earlier order comes first (FIFO)\n        return order > other.order;\n    }\n};\n\nclass ThreadPool {\npublic:\n\n\n    ThreadPool(size_t numThreads)\n        : stop_(false)\n    {\n        for(size_t i = 0;i<numThreads;++i)\n            workers_.emplace_back(\n                [this]\n                {\n                    while(true)\n                    {\n                        std::function<void()> task;\n\n                        {\n                            std::unique_lock<std::mutex> lock(this->queueMutex_);\n                            this->condition_.wait(lock, \n                                [this]{ return this->stop_.load() || !this->tasks_.empty(); });\n                            if(this->stop_.load() && this->tasks_.empty())\n                                return;\n                            task = std::move(this->tasks_.front());\n                            this->tasks_.pop();\n                        }\n\n                        task();\n                    }\n                }\n            );\n    }\n\n    ~ThreadPool()\n    {\n        shutdown();\n    }\n\n    void shutdown()\n    {\n        {\n            std::unique_lock<std::mutex> lock(queueMutex_);\n            stop_.store(true);\n        }\n        condition_.notify_all();\n        for(std::thread &worker: workers_)\n            if(worker.joinable())\n                worker.join();\n    }\n\n\n    template <class F, class... Args>\n    auto ThreadPool::submit(F&& f, Args&&... args) \n        -> std::future<typename std::result_of<F(Args...)>::type>\n    {\n        using return_type = typename std::result_of<F(Args...)>::type;\n\n        auto task = std::make_shared< std::packaged_task<return_type()> >(\n            std::bind(std::forward<F>(f), std::forward<Args>(args)...)\n        );\n\n        std::future<return_type> res = task->get_future();\n        {\n            std::unique_lock<std::mutex> lock(queueMutex_);\n\n            // Don't allow enqueueing after stopping the pool\n            if(stop_) {\n                throw std::runtime_error(\"Submit on stopped ThreadPool\");\n            }\n\n            tasks_.emplace([task](){ (*task)(); });\n        }\n        condition_.notify_one();\n        return res;\n    }\n\n    size_t getTaskQueueSize() const{\n\n    }\n\n    size_t getActiveThreadCount() const{\n\n    }\n\n    size_t getTotalTasksExecuted() const{\n        \n    }\n\n\nprotected:\n    // Worker threads\n    std::vector<std::thread> workers_;\n\n    // Task queue\n    std::queue<std::function<void()>> tasks_;\n\n    // Synchronization\n    std::mutex queueMutex_;\n    std::condition_variable condition_;\n    std::atomic<bool> stop_;\n};\n\n\n#endif // THREADPOOL_H\n\n```\n\nPrompt:\n\nEnhance the provided ThreadPool class to support advanced features such as task prioritization, dynamic resizing, task dependencies, and improved monitoring. Additionally, ensure robust thread safety and optimize performance for high-concurrency scenarios. Return the entire code along with your modifications. Do not implement the main function.\n\n\nDynamic Resizing\n- Implement `void resize(size_t newSize);` as a public method in the class to adjust worker threads.\n- If newSize > current size, spawn additional threads.\n- If newSize < current size, gracefully terminate excess threads after their current tasks.\n\nTask Prioritization\n- Introduce three priority levels: High, Medium, Low.\n- Modify the submit method(s) to accept a Priority parameter so that higher\u2010priority tasks run first.\n- Within the same priority, tasks should run in FIFO order.\n\nTask Dependencies\nImplement two overloading `submit` methods.\n\n- 1. Submit a task without dependencies\ntemplate <class F, class... Args>\nauto submit(Priority priority, F&& f, Args&&... args)\n    -> std::future<typename std::result_of<F(Args...)>::type>;\n\n- 2. Submit a task with dependencies\ntemplate <class F, class... Args>\nauto submit(Priority priority,\n            std::vector<std::future<void>>&& dependencies,\n            F&& f, Args&&... args)\n    -> std::future<typename std::result_of<F(Args...)>::type>;\n\nThese two overloads must be used exactly in the updated class. The first version accepts only a Priority and a callable with arguments, and the second accepts a Priority, a vector of std::future<void>, and a callable with arguments. Do not alter these signatures or templates.\n\nMonitoring Methods\n- size_t getTaskQueueSize() const; returns the number of tasks waiting in the queue.\n- size_t getActiveThreadCount() const; returns the number of threads actively executing tasks.\n- size_t getTotalTasksExecuted() const; returns how many tasks have executed since the pool was created.\n\nThread Safety and Performance\n- Use robust synchronization (mutexes, atomics) to avoid data races.\n- Optimize for high concurrency and large numbers of tasks.\n"
}